{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelwnau/ai_academy_notebooks/blob/main/TF_IDF_Calculations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8aeff8a2",
      "metadata": {
        "id": "8aeff8a2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e5edac47",
      "metadata": {
        "id": "e5edac47"
      },
      "outputs": [],
      "source": [
        "#The corpus of text with four different documents\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "664e254d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "664e254d",
        "outputId": "02c9b1ad-3830-4697-bb53-1fdd4ad08e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 4, 'is': 4, 'the': 4, 'first': 2, 'document': 4, 'second': 1, 'and': 1, 'third': 1, 'one': 1}\n",
            "[{'this': 1, 'is': 1, 'the': 1, 'first': 1, 'document': 1}, {'this': 1, 'document': 2, 'is': 1, 'the': 1, 'second': 1}, {'and': 1, 'this': 1, 'is': 1, 'the': 1, 'third': 1, 'one': 1}, {'is': 1, 'this': 1, 'the': 1, 'first': 1, 'document': 1}]\n"
          ]
        }
      ],
      "source": [
        "#This section will calculate the term frequency for each sentence and the whole corpus\n",
        "\n",
        "word_freq = {} #this is the total word frequency for all documents\n",
        "sent_freq = {} #this is the frequency of each word in each sentence\n",
        "sent_word_freq = [] #this is a list of all sent freq together\n",
        "\n",
        "for sentence in corpus:\n",
        "    words = sentence.strip(\".?\").split(\" \")\n",
        "    sent_freq = {} #reset the individual sentence frequency\n",
        "    for word in words:\n",
        "        if word.lower() not in sent_freq.keys():\n",
        "            sent_freq[word.lower()] = 0\n",
        "        sent_freq[word.lower()] += 1\n",
        "        \n",
        "        if word.lower() not in word_freq.keys():\n",
        "            word_freq[word.lower()] = 0\n",
        "        word_freq[word.lower()] += 1\n",
        "    sent_word_freq.append(sent_freq)\n",
        "\n",
        "print(word_freq)\n",
        "print(sent_word_freq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6d2b71e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d2b71e3",
        "outputId": "e70695e5-b236-4dec-b264-a8241193c5e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 1.0, 'is': 1.0, 'the': 1.0, 'first': 1.5108256237659907, 'document': 1.2231435513142097, 'second': 1.916290731874155, 'and': 1.916290731874155, 'third': 1.916290731874155, 'one': 1.916290731874155}\n"
          ]
        }
      ],
      "source": [
        "total_documents = len(corpus) #get the total number of documents\n",
        "inv_doc_freq = {} #dictionary of each word with the inverse document frequency\n",
        "#doc_contain_word = 0\n",
        "\n",
        "#compute the inverse document frequency via: ln((1+total documents)/(1+ # docs containing word))+1\n",
        "for key in word_freq.keys():\n",
        "    doc_contain_word = 0\n",
        "    for sentence in sent_word_freq:\n",
        "        if key in sentence:\n",
        "            doc_contain_word += 1\n",
        "\n",
        "    inv_doc_freq[key] = math.log(float(1+total_documents)/float(doc_contain_word+1))+1\n",
        "    \n",
        "print(inv_doc_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cef78ca2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cef78ca2",
        "outputId": "92bad2eb-90c0-4636-d94a-49eaa6e01166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'this': 1.0, 'is': 1.0, 'the': 1.0, 'first': 1.5108256237659907, 'document': 1.2231435513142097}, {'this': 1.0, 'document': 2.4462871026284194, 'is': 1.0, 'the': 1.0, 'second': 1.916290731874155}, {'and': 1.916290731874155, 'this': 1.0, 'is': 1.0, 'the': 1.0, 'third': 1.916290731874155, 'one': 1.916290731874155}, {'is': 1.0, 'this': 1.0, 'the': 1.0, 'first': 1.5108256237659907, 'document': 1.2231435513142097}]\n"
          ]
        }
      ],
      "source": [
        "un_norm_tfidf = {} #this will contain the un normalized TF IDF for 1 sentence\n",
        "un_norm_sent_tfidf = [] #this will contain a list of all sentences\n",
        "\n",
        "#this will compute the TF IDF by multiplying the TF with the IDF computed above\n",
        "#it is a raw score\n",
        "for sentence in sent_word_freq:\n",
        "    un_norm_tfidf = {}\n",
        "    for key in sentence.keys():\n",
        "        un_norm_tfidf[key] = float(sentence[key]) * inv_doc_freq[key]\n",
        "    un_norm_sent_tfidf.append(un_norm_tfidf)\n",
        "\n",
        "print(un_norm_sent_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d67b8930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d67b8930",
        "outputId": "43a9bae3-bfd3-44ef-b2e4-ad3f05fec6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'this': 0.38408524091481483, 'is': 0.38408524091481483, 'the': 0.38408524091481483, 'first': 0.5802858236844359, 'document': 0.46979138557992045}, {'this': 0.281088674033753, 'document': 0.6876235979836938, 'is': 0.281088674033753, 'the': 0.281088674033753, 'second': 0.5386476208856763}, {'and': 0.511848512707169, 'this': 0.267103787642168, 'is': 0.267103787642168, 'the': 0.267103787642168, 'third': 0.511848512707169, 'one': 0.511848512707169}, {'is': 0.38408524091481483, 'this': 0.38408524091481483, 'the': 0.38408524091481483, 'first': 0.5802858236844359, 'document': 0.46979138557992045}]\n"
          ]
        }
      ],
      "source": [
        "#this section will normailize the TF IDF scores\n",
        "\n",
        "normalized_sent_tfidf = []\n",
        "sentence_SS = []\n",
        "\n",
        "for sentence in un_norm_sent_tfidf:\n",
        "    squared_total_sum_sent = 0\n",
        "    for key in sentence:\n",
        "        squared_total_sum_sent += sentence[key]**2\n",
        "    squared_total_sum_sent = math.sqrt(squared_total_sum_sent)\n",
        "    sentence_SS.append(squared_total_sum_sent)\n",
        "\n",
        "index = 0\n",
        "for sentence in un_norm_sent_tfidf:\n",
        "    temp_sentence = {}\n",
        "    for key in sentence:\n",
        "        temp_sentence[key] = sentence[key]/sentence_SS[index]\n",
        "        \n",
        "    normalized_sent_tfidf.append(temp_sentence)\n",
        "    index += 1\n",
        "    \n",
        "print(normalized_sent_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "133ba67b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "133ba67b",
        "outputId": "f980462d-c4f5-443b-f3d3-6134cf115671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 9)\n",
            "[[0.     0.4698 0.5803 0.3841 0.     0.     0.3841 0.     0.3841]\n",
            " [0.     0.6876 0.     0.2811 0.     0.5386 0.2811 0.     0.2811]\n",
            " [0.5118 0.     0.     0.2671 0.5118 0.     0.2671 0.5118 0.2671]\n",
            " [0.     0.4698 0.5803 0.3841 0.     0.     0.3841 0.     0.3841]]\n"
          ]
        }
      ],
      "source": [
        "#This is the code for calculating TF IDF with python libraries\n",
        "#The array generated is not normalized - if you normalize it, you will get the same values as above\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(X.shape)\n",
        "np.set_printoptions(precision=4)\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "70dedcf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70dedcf5",
        "outputId": "c2e49ecd-91d8-43c6-e388-0c70fe2c1559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
              "       'this'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5cc9a0b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cc9a0b5",
        "outputId": "29c88edd-05f9-42fd-a740-dfef66d4daca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the first document.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 0.0,\n",
              " 'document': 0.46979138557992045,\n",
              " 'first': 0.5802858236844359,\n",
              " 'is': 0.38408524091481483,\n",
              " 'one': 0.0,\n",
              " 'second': 0.0,\n",
              " 'the': 0.38408524091481483,\n",
              " 'third': 0.0,\n",
              " 'this': 0.38408524091481483}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "print(corpus[0])\n",
        "dict(zip(vectorizer.get_feature_names_out(),X.toarray()[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3181104",
      "metadata": {
        "id": "e3181104"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}