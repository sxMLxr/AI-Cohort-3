{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelwnau/ai_academy_notebooks/blob/main/WKS8_nau_tues_Student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFB1YQP9IvMk"
      },
      "source": [
        "# Workshop 8: Linear Regression\n",
        "\n",
        "\n",
        "In this exercise, you will apply linear regression and Lasso regression methods to the dataset supplied to you, and then compare their results to determine whether Lasso regression is needed for this dataset:\n",
        "\n",
        "**Dataset description**: You are provided a dataset with 20 variables. Variables $x1\\ -\\ x19$ refer to the independent variables, while variable $y$ is your dependent variable. Training data is stored in the file `/etc/data/regression-train.csv`.\n",
        "\n",
        "**Note**: The TA will use a test set to verify your solution. The format (independent variables $x1\\ -\\ x19$, dependent variable  $y$) will be same, but TA's file may contain different number of data points than the split version from training set. Please ensure you take this into account, and do not hard code any dimensions.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BasqG0PLdhri",
        "outputId": "b91e731d-e2f9-402f-8860-36fe23d4acd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-09b96daf1e0cf44e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pP4YN8qTIvMm"
      },
      "outputs": [],
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-bb0404ec9da83a2b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "mmV22BDHIvMn",
        "outputId": "de1a8281-1c9a-497d-ae23-ee4ceaa88830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       x1   x2   x3    x4   x5   x6  x7  x8   x9  x10  x11  x12  x13   x14  \\\n",
              "0     508   44   60   718   42  234   0   0   56   52    8  216    0  1998   \n",
              "1    1020  106  198  1620  126  680   2   2  112  104   36  614    0  5744   \n",
              "2    1118  146  828   704   32  698   2   2   96  122   18  842    0  6324   \n",
              "3     922   70  452   222   48  150   0   0  108  108   22  152    2  1360   \n",
              "4     526   60  294   162   18  164   2   2   52   46    8  166    0  1776   \n",
              "..    ...  ...  ...   ...  ...  ...  ..  ..  ...  ...  ...  ...  ...   ...   \n",
              "127   630   50   78   996   48  188   2   2   70  120   26  136    0  1260   \n",
              "128   330   32   38   664    4   20   0   2   26   18    4   36    2   392   \n",
              "129  1146  156  262  2628  194  840   0   0  170  120   24  940    0  6396   \n",
              "130   472   22  398   250    2  128   0   0   54   30   26  232    2  2230   \n",
              "131  1120  132   18   664  130  520   2   2  178  192   16  466    2  3578   \n",
              "\n",
              "      x15  x16  x17  x18  x19       y  \n",
              "0     472  136  236   12    4   610.0  \n",
              "1    1642  294  348   14   20  2300.0  \n",
              "2    1748  282  718   16    4  1850.0  \n",
              "3     320  224   98    4   36   270.0  \n",
              "4     440  140  172    8    2   500.0  \n",
              "..    ...  ...  ...  ...  ...     ...  \n",
              "127   302  152  110    6   26   310.0  \n",
              "128    88   78   36    6    4   150.0  \n",
              "129  1714  288  664   16   18  1920.0  \n",
              "130   540  112  114    8    0   460.0  \n",
              "131   940  322  310    8   52  1250.0  \n",
              "\n",
              "[132 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42b38219-0e65-4895-9b3d-1747b7affdad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>x15</th>\n",
              "      <th>x16</th>\n",
              "      <th>x17</th>\n",
              "      <th>x18</th>\n",
              "      <th>x19</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>508</td>\n",
              "      <td>44</td>\n",
              "      <td>60</td>\n",
              "      <td>718</td>\n",
              "      <td>42</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>8</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>1998</td>\n",
              "      <td>472</td>\n",
              "      <td>136</td>\n",
              "      <td>236</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>610.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1020</td>\n",
              "      <td>106</td>\n",
              "      <td>198</td>\n",
              "      <td>1620</td>\n",
              "      <td>126</td>\n",
              "      <td>680</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>112</td>\n",
              "      <td>104</td>\n",
              "      <td>36</td>\n",
              "      <td>614</td>\n",
              "      <td>0</td>\n",
              "      <td>5744</td>\n",
              "      <td>1642</td>\n",
              "      <td>294</td>\n",
              "      <td>348</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>2300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1118</td>\n",
              "      <td>146</td>\n",
              "      <td>828</td>\n",
              "      <td>704</td>\n",
              "      <td>32</td>\n",
              "      <td>698</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>96</td>\n",
              "      <td>122</td>\n",
              "      <td>18</td>\n",
              "      <td>842</td>\n",
              "      <td>0</td>\n",
              "      <td>6324</td>\n",
              "      <td>1748</td>\n",
              "      <td>282</td>\n",
              "      <td>718</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>1850.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>922</td>\n",
              "      <td>70</td>\n",
              "      <td>452</td>\n",
              "      <td>222</td>\n",
              "      <td>48</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>108</td>\n",
              "      <td>108</td>\n",
              "      <td>22</td>\n",
              "      <td>152</td>\n",
              "      <td>2</td>\n",
              "      <td>1360</td>\n",
              "      <td>320</td>\n",
              "      <td>224</td>\n",
              "      <td>98</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>270.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>526</td>\n",
              "      <td>60</td>\n",
              "      <td>294</td>\n",
              "      <td>162</td>\n",
              "      <td>18</td>\n",
              "      <td>164</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>46</td>\n",
              "      <td>8</td>\n",
              "      <td>166</td>\n",
              "      <td>0</td>\n",
              "      <td>1776</td>\n",
              "      <td>440</td>\n",
              "      <td>140</td>\n",
              "      <td>172</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>630</td>\n",
              "      <td>50</td>\n",
              "      <td>78</td>\n",
              "      <td>996</td>\n",
              "      <td>48</td>\n",
              "      <td>188</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>70</td>\n",
              "      <td>120</td>\n",
              "      <td>26</td>\n",
              "      <td>136</td>\n",
              "      <td>0</td>\n",
              "      <td>1260</td>\n",
              "      <td>302</td>\n",
              "      <td>152</td>\n",
              "      <td>110</td>\n",
              "      <td>6</td>\n",
              "      <td>26</td>\n",
              "      <td>310.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>330</td>\n",
              "      <td>32</td>\n",
              "      <td>38</td>\n",
              "      <td>664</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>392</td>\n",
              "      <td>88</td>\n",
              "      <td>78</td>\n",
              "      <td>36</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>1146</td>\n",
              "      <td>156</td>\n",
              "      <td>262</td>\n",
              "      <td>2628</td>\n",
              "      <td>194</td>\n",
              "      <td>840</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>170</td>\n",
              "      <td>120</td>\n",
              "      <td>24</td>\n",
              "      <td>940</td>\n",
              "      <td>0</td>\n",
              "      <td>6396</td>\n",
              "      <td>1714</td>\n",
              "      <td>288</td>\n",
              "      <td>664</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>1920.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>472</td>\n",
              "      <td>22</td>\n",
              "      <td>398</td>\n",
              "      <td>250</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>30</td>\n",
              "      <td>26</td>\n",
              "      <td>232</td>\n",
              "      <td>2</td>\n",
              "      <td>2230</td>\n",
              "      <td>540</td>\n",
              "      <td>112</td>\n",
              "      <td>114</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>460.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>1120</td>\n",
              "      <td>132</td>\n",
              "      <td>18</td>\n",
              "      <td>664</td>\n",
              "      <td>130</td>\n",
              "      <td>520</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>178</td>\n",
              "      <td>192</td>\n",
              "      <td>16</td>\n",
              "      <td>466</td>\n",
              "      <td>2</td>\n",
              "      <td>3578</td>\n",
              "      <td>940</td>\n",
              "      <td>322</td>\n",
              "      <td>310</td>\n",
              "      <td>8</td>\n",
              "      <td>52</td>\n",
              "      <td>1250.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42b38219-0e65-4895-9b3d-1747b7affdad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42b38219-0e65-4895-9b3d-1747b7affdad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42b38219-0e65-4895-9b3d-1747b7affdad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Read the data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AI ACADEMY/2 - Data Mining/8- Week 8/WKS8_Student/data/regression-train.csv\")\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-eef1468ef64e4e98",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3Omm-d7dIvMn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7dmwSntKIvMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e6b18e-42ab-4c2a-bb81-14d7fe272f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.55646407  0.15658678  0.96233481 -0.71601746  0.76470622  0.50389386\n",
            "  0.93541435  0.93541435 -0.12200241  0.78852431  1.206875    0.12092592\n",
            " -1.04880885  0.40219789  0.30992371  0.13755462  0.10537768  0.09601967\n",
            "  0.81641649]\n"
          ]
        }
      ],
      "source": [
        "# For regression, it is particularly important to normalize our data before\n",
        "# training the model, so we can better interpret our coefficients\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_unscaled)\n",
        "X_train = scaler.transform(X_train_unscaled)\n",
        "X_test = scaler.transform(X_test_unscaled)\n",
        "print(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZeXcdAPIvMo"
      },
      "source": [
        "We have given you a function to caculate the RMSE of a regression model, given its predictions and the ground truth y-values of the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2d1c351adc22eb14",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0am7td8VIvMo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    # Inputs:\n",
        "    # y_true: ground truth dependent variable values, of type vector\n",
        "    # y_pred: prediction outcomes from any regression method, with the same length as y_true\n",
        "\n",
        "    # Outputs:\n",
        "    # a single value of type double, with the RMSE value\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    return np.sqrt(np.mean((y_true - y_pred)**2))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Define the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = calculate_rmse(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92QJ5jPSlXzK",
        "outputId": "27d4b9c8-da6b-4095-8d8d-0e2295cd6d79"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 787.9099436300614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW-iWUsOIvMo"
      },
      "source": [
        "## Part 1: Linear Regression (Group)\n",
        "You will write code in the function `alda_regression_linear` to train simple linear regression. Detailed instructions for implementation and allowed packages have been provided the comments.\n",
        "\n",
        "Before your begin, read the documentation on sklearn's [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "alda_regression_linear",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "hT210STcIvMo"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def alda_regression_linear(X_train, X_test, y_train):\n",
        "    # Perform linear regression\n",
        "    # Inputs:\n",
        "    # X_train: training data frame(19 variables, x1-x19)\n",
        "    # X_test: test data frame(19 variables, x1-x19)\n",
        "    # y_train: dependent variable, training data (vector, continous type)\n",
        "\n",
        "    # Output:\n",
        "    # A tuple containing:\n",
        "    # - The regression model and \n",
        "    # - The list of predictions on test data (X_test) (vector) \n",
        "  \n",
        "    # allowed packages: sklearn.linear_model\n",
        "  \n",
        "    # Function hints: Read the documentation for the functions LinearRegression (link above)\n",
        "    \n",
        "    # write code for building a linear regression model using X_train, y_train\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def alda_regression_linear(X_train, X_test, y_train):\n",
        "    # Perform linear regression\n",
        "    # Inputs:\n",
        "    # X_train: training data frame(19 variables, x1-x19)\n",
        "    # X_test: test data frame(19 variables, x1-x19)\n",
        "    # y_train: dependent variable, training data (vector, continuous type)\n",
        "\n",
        "    # Output:\n",
        "    # A tuple containing:\n",
        "    # - The regression model and \n",
        "    # - The list of predictions on test data (X_test) (vector) \n",
        "\n",
        "    # Define the model\n",
        "    model = LinearRegression()\n",
        "    # Here we're defining our model as a LinearRegression model. Linear Regression is \n",
        "    # a simple machine learning model where the response y is modelled by a linear \n",
        "    # combination of the predictors in X.\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    # The fit method here is used to train the model. We're passing in the X_train which \n",
        "    # contains our predictor variables and the y_train which contains our output variable. \n",
        "    # The fit method adjusts weights on the input variables to find the best possible \n",
        "    # coefficients that minimize the loss (in this case, mean squared error).\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "    # After we've fitted the model, we can make predictions on our test data. \n",
        "    # The predict method takes in the X_test data and tries to predict the output \n",
        "    # for each row in X_test based on the coefficients it learned in the training phase.\n",
        "\n",
        "    return model, y_pred\n",
        "    # The function returns a tuple: the model itself (which contains coefficients \n",
        "    # for each input feature) and the predictions it made on the test dataset.\n"
      ],
      "metadata": {
        "id": "xBltQBeAn2BP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K7lefif4IvMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6131fc90-0dbd-4142-f9f9-4c6af38cd5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RMSE: 524.953283852617\n",
            "Test RMSE: 787.9099436300614\n",
            "\n",
            "Model coefficients:\n",
            "[   48.18082989    65.73979512   210.77335056   122.5616241\n",
            "   124.07603501   290.38608009   123.86744484   -83.03161175\n",
            "   270.17717717   -48.56806094   -23.51778917  -941.63419412\n",
            "   -89.00842661 -4044.98292672  5073.44151699  -544.21209605\n",
            "   137.73175811  -101.04154575   235.26578305]\n"
          ]
        }
      ],
      "source": [
        "# Now test your model\n",
        "lr_model, lr_predictions = alda_regression_linear(X_train, X_test, y_train)\n",
        "\n",
        "print(f'Training RMSE: {calculate_rmse(y_train, lr_model.predict(X_train))}')\n",
        "print(f'Test RMSE: {calculate_rmse(y_test, lr_predictions)}')\n",
        "print('')\n",
        "\n",
        "# Which attributes are most predictive of the outcome variable?\n",
        "print(f'Model coefficients:\\n{lr_model.coef_}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "alda_regression_linear-public",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "RY_4fD55IvMp"
      },
      "outputs": [],
      "source": [
        "lr_model, simple_linear_regression_result = alda_regression_linear(X_train, X_test, y_train)\n",
        "np.testing.assert_equal(simple_linear_regression_result.shape, (27,))\n",
        "np.testing.assert_almost_equal(calculate_rmse(y_test,simple_linear_regression_result),787.9099436300563)\n",
        "np.testing.assert_almost_equal(lr_model.coef_[0], 48.18082989)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "alda_regression_linear-private",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "V77F5d5wIvMp"
      },
      "outputs": [],
      "source": [
        "# Here's some test cases to make sure you're right\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/AI ACADEMY/2 - Data Mining/8- Week 8/WKS8_Student/data/regression-test.csv\")\n",
        "X_test2 = df_test.iloc[:,:-1]\n",
        "y_test2 = df_test.iloc[:,-1]\n",
        "\n",
        "lr_model, simple_linear_regression_result = alda_regression_linear(X, X_test2, y)\n",
        "np.testing.assert_equal(simple_linear_regression_result.shape, (66,))\n",
        "np.testing.assert_almost_equal(calculate_rmse(y_test2,simple_linear_regression_result),946.4318403560575)\n",
        "# END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQrWLfxrIvMp"
      },
      "source": [
        "## Part 2: Lasso Regression (Group)\n",
        "You will write code in the function `alda_regression_lasso` to train simple lasso regression. Detailed instructions for implementation and allowed packages have been provided the comments. \n",
        "\n",
        "Before your begin, read the documentation on sklearn's [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) - a Lasso regression model that uses CV to tune its hyperparameters.\n",
        "\n",
        "**Note** that the lasso regression model has *built-in* crossvalidation, which it performs on the training dataset provided, to select the best shrinkage coefficient for the validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "alda_regression_lasso",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "nnU_-UVcIvMq"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "def alda_regression_lasso(X_train, X_test, y_train, random_state=0):\n",
        "    # Instantiate the LassoCV model with 10-fold cross validation\n",
        "    #lasso_cv = LassoCV(cv=10, random_state=random_state)\n",
        "    lasso_cv = LassoCV(cv=10, random_state=random_state, max_iter=10000)\n",
        "    #lasso_cv = LassoCV(cv=10, random_state=random_state, max_iter=10000, tol=0.0001)\n",
        "\n",
        "\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    lasso_cv.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions on the test data\n",
        "    y_pred = lasso_cv.predict(X_test)\n",
        "    \n",
        "    # Return the fitted model and the predictions\n",
        "    return lasso_cv, y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Fjy-PeIvMq"
      },
      "source": [
        "**Before testing your model**: Do you expect the training error to be higher or lower? What about the testing error? What do you expect to be different about the coefficients?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lkd_qOlSIvMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc16a962-f91e-4770-9083-01e2e32fff3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RMSE: 541.6564802479181\n",
            "Test RMSE: 639.6168267325154\n",
            "\n",
            "Model coefficients:\n",
            "[ -201.26105526   125.5739836    143.30724503   113.59035547\n",
            "     0.           452.53752144    78.21118683   -28.92898297\n",
            "    -0.            -8.80656266     0.           -91.57679107\n",
            "   -95.58105028 -2134.97942061  2431.93701951    -0.\n",
            "    -0.          -153.36709652   172.02434475]\n",
            "\n",
            "The shinkage coefficient hyperparameter chosen by CV: 3.196361962538218\n"
          ]
        }
      ],
      "source": [
        "lasso_model, lasso_predictions = alda_regression_lasso(X_train, X_test, y_train)\n",
        "\n",
        "# Should be ~541.7\n",
        "print(f'Training RMSE: {calculate_rmse(y_train, lasso_model.predict(X_train))}')\n",
        "# Should be ~639.6\n",
        "print(f'Test RMSE: {calculate_rmse(y_test, lasso_predictions)}')\n",
        "print('')\n",
        "\n",
        "# Which attributes are most predictive of the outcome variable?\n",
        "print(f'Model coefficients:\\n{lasso_model.coef_}')\n",
        "\n",
        "print()\n",
        "# Note we called this 'lamda' in class, but sklearn calls it alpha (should be ~3.196)\n",
        "print(f'The shinkage coefficient hyperparameter chosen by CV: {lasso_model.alpha_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "alda_regression_lasso-public",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "VHk-tdAwIvMq"
      },
      "outputs": [],
      "source": [
        "lasso_model, lasso_regression_result = alda_regression_lasso(X_train, X_test, y_train)\n",
        "np.testing.assert_equal(lasso_regression_result.shape, (27,))\n",
        "np.testing.assert_almost_equal(calculate_rmse(y_test, lasso_regression_result), 639.6168267325169)\n",
        "np.testing.assert_almost_equal(lasso_model.coef_[0], -201.26105526)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "alda_regression_lasso-private",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "jxo6zPb4IvMq"
      },
      "outputs": [],
      "source": [
        "# Test Cases\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/AI ACADEMY/2 - Data Mining/8- Week 8/WKS8_Student/data/regression-test.csv\")\n",
        "X_test2 = df_test.iloc[:,:-1]\n",
        "y_test2 = df_test.iloc[:,-1]\n",
        "\n",
        "lasso_model, lasso_regression_result = alda_regression_lasso(X, X_test2, y)\n",
        "np.testing.assert_equal(lasso_regression_result.shape, (66,))\n",
        "np.testing.assert_almost_equal(calculate_rmse(y_test2, lasso_regression_result), 978.6205927267488)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-59f0827753c683dc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3Q3O45XqIvMq"
      },
      "source": [
        "From the results, compare the two regression models, including the training and testing RMSE, and the coefficients. Use the output of these functions to answer the following questions below:\n",
        "\n",
        "1. The dataset contains 19 attributes. Are all 19 attributes useful for predicting the dependent variable? Why or why not? Use your results to justify the answer.\n",
        "2. If not all attributes are predictive, use your Lasso model to perform feature selection. Which attributes should be kept? Use a correlation and/or scatter plot to justify your answer for at least one attribute (in a new cell below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "comparison",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "m58tZAAwIvMq"
      },
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}