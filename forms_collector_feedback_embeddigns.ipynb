{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1P8Zg4eQnPJC9WmwJ4CPfLFj9K5KS98Jt",
      "authorship_tag": "ABX9TyOXlPiXCju2CI1pH7raHnPG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelwnau/ai_academy_notebooks/blob/main/forms_collector_feedback_embeddigns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "ng58b4T2juYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTAWtE07f6o6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "# Load the excel data into a DataFrame\n",
        "data = pd.read_excel(\"<LINK TO YOUR FILE IN GOOGLE DRIVE OR WHEREVER>\")\n",
        "\n",
        "# Display the first few rows of the data to understand its structure and content\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new excel data into a DataFrame\n",
        "feedback = pd.read_excel(\"<LINK TO YOUR FILE IN GOOGLE DRIVE OR WHEREVER>\")\n",
        "\n",
        "# Display the first few rows of the data to understand its structure and content\n",
        "feedback.head()\n"
      ],
      "metadata": {
        "id": "2PnfZxy_gGcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine both datasets to get a holistic view\n",
        "combined_data = pd.concat([data, feedback], axis=1)\n",
        "\n",
        "# Here are the columns we'll be focusing on for generating the personas. In this instantiation, they should be hand copied into this\n",
        "columns_of_interest = {\n",
        "    'feedback': [\n",
        "        <plain text of the feedback>,\n",
        "        <plain text of the feedback>,\n",
        "        <plain text of the feedback>\n",
        "    ],\n",
        "    'embeddings': [\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Filter the combined dataset\n",
        "filtered_data = combined_data[list(columns_of_interest.keys())]\n",
        "print(filtered_data.head())\n",
        "\n",
        "\n",
        "\n",
        "# Let's summarize the data to identify common themes or patterns\n",
        "# We'll begin by creating a frequency distribution of key terms or phrases from the responses\n",
        "from collections import defaultdict\n",
        "\n",
        "# Initialize a frequency dictionary\n",
        "frequency = defaultdict(int)\n",
        "\n",
        "# Iterate through the responses and count the occurrences of key terms or phrases\n",
        "for column in filtered_data.columns:\n",
        "    for response in filtered_data[column]:\n",
        "        # Convert the response to string to handle NaN values and split it into words\n",
        "        words = str(response).split()\n",
        "        for word in words:\n",
        "            frequency[word.lower()] += 1\n",
        "\n",
        "# Get the top 20 most common words to understand the themes in the responses\n",
        "top_words = sorted(frequency.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "top_words\n"
      ],
      "metadata": {
        "id": "cV3NMS0JgKp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the responses will be tokenized for vector embedding. First we concatenate the responses from `filtered_data` into a string\n",
        "responses = filtered_data.fillna('').astype(str).apply(' '.join, axis=1).tolist()\n"
      ],
      "metadata": {
        "id": "u5dvjvYX8-rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to set your OpenAI API key here\n",
        "openai.api_key = '<OPENAI API KEY>'\n",
        "\n",
        "\n",
        "\n",
        "def get_embeddings(texts):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        response = openai.Embedding.create(model=\"text-embedding-ada-002\", input=text)\n",
        "        embedding_vector = response.data[0][\"embedding\"]\n",
        "        embeddings.append(embedding_vector)\n",
        "    return embeddings\n"
      ],
      "metadata": {
        "id": "i_2n-00hD4Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# NOTE: Uncomment and execute in your environment\n",
        "embeddings_list = get_embeddings_corrected(feedback)\n",
        "\n",
        "# Step 2: Combine the text from `feedback` with its corresponding embedding\n",
        "# Assuming feedback is a pandas Series and embeddings_list is a list of lists\n",
        "combined_data = pd.concat([feedback.reset_index(drop=True),\n",
        "                            pd.DataFrame(embeddings_list, columns=[f\"dim_{i}\" for i in range(len(embeddings_list[0]))])],\n",
        "                           axis=1)\n",
        "\n",
        "# Step 3: Save the combined data to the specified Excel file\n",
        "output_path = \"<LINK TO YOUR FILE IN GOOGLE DRIVE OR WHEREVER>\"\n",
        "combined_data.to_excel(output_path, index=False)\n",
        "\n",
        "output_path\n"
      ],
      "metadata": {
        "id": "XPd0EAegFaGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_embeddings = pd.DataFrame(feedback)\n",
        "df_embeddings.to_csv('< RENAME YOUR FILE >-1.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "V1dJQ43YEHxm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}